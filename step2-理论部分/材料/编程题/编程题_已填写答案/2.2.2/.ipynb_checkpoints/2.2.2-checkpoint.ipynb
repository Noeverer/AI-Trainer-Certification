{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fea81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement  ... model year  origin                   car name\n",
      "0  18.0          8         307.0  ...         70       1  chevrolet chevelle malibu\n",
      "1  15.0          8         350.0  ...         70       1          buick skylark 320\n",
      "2  18.0          8         318.0  ...         70       1         plymouth satellite\n",
      "3  16.0          8         304.0  ...         70       1              amc rebel sst\n",
      "4  17.0          8         302.0  ...         70       1                ford torino\n",
      "\n",
      "[5 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/2d/1492rc7n7dz6gn_cpfbv90800000gn/T/ipykernel_64046/4056706165.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 创建包含标准化和线性回归的管道\u001b[39;00m\n\u001b[32m     29\u001b[39m pipeline = Pipeline([(\u001b[33m'scaler'\u001b[39m, StandardScaler),(\u001b[33m'linreg'\u001b[39m, LinearRegression)])\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m pipeline.fit(X_train,y_train)\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 保存训练好的模型\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m open(\u001b[33m'2.2.2_model.pkl'\u001b[39m, \u001b[33m'wb'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m model_file:\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1347\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1348\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1349\u001b[39m                 )\n\u001b[32m   1350\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    467\u001b[39m         self : object\n\u001b[32m    468\u001b[39m             Pipeline \u001b[38;5;28;01mwith\u001b[39;00m fitted steps.\n\u001b[32m    469\u001b[39m         \"\"\"\n\u001b[32m    470\u001b[39m         routed_params = self._check_method_params(method=\u001b[33m\"fit\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m         Xt = self._fit(X, y, routed_params)\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"Pipeline\"\u001b[39m, self._log_message(len(self.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    473\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._final_estimator != \u001b[33m\"passthrough\"\u001b[39m:\n\u001b[32m    474\u001b[39m                 last_step_params = routed_params[self.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]]\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, routed_params)\u001b[39m\n\u001b[32m    404\u001b[39m                 cloned_transformer = transformer\n\u001b[32m    405\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    406\u001b[39m                 cloned_transformer = clone(transformer)\n\u001b[32m    407\u001b[39m             \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    409\u001b[39m                 cloned_transformer,\n\u001b[32m    410\u001b[39m                 X,\n\u001b[32m    411\u001b[39m                 y,\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/joblib/memory.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.func(*args, **kwargs)\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1299\u001b[39m     \"\"\"\n\u001b[32m   1300\u001b[39m     params = params \u001b[38;5;28;01mor\u001b[39;00m {}\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1302\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m hasattr(transformer, \u001b[33m\"fit_transform\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m             res = transformer.fit_transform(X, y, **params.get(\u001b[33m\"fit_transform\"\u001b[39m, {}))\n\u001b[32m   1304\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1305\u001b[39m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n\u001b[32m   1306\u001b[39m                 X, **params.get(\u001b[33m\"transform\"\u001b[39m, {})\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/utils/_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m     @wraps(f)\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    275\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    276\u001b[39m             return_tuple = (\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1057\u001b[39m                 )\n\u001b[32m   1058\u001b[39m \n\u001b[32m   1059\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1060\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m   1062\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1063\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m   1064\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "# 显示前五行数据\n",
    "print(df.head())\n",
    "\n",
    "# 处理缺失值\n",
    "# 将 'horsepower' 列中的所有值转换为数值类型\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "# 删除包含缺失值的行\n",
    "df = df.dropna()\n",
    "\n",
    "# 选择相关特征进行建模（定义自变量（返回一个DataFrame）和因变量）\n",
    "X = df.drop(['mpg', 'car name'], axis=1)\n",
    "y = df['mpg']\n",
    "\n",
    "# 将数据集划分为训练集和测试集（测试集占比20%）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建包含标准化和线性回归的管道\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),('linreg', LinearRegression())])\n",
    "\n",
    "# 训练模型\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "# 保存训练好的模型\n",
    "with open('2.2.2_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(pipeline, model_file)\n",
    "\n",
    "# 预测并保存结果\n",
    "y_pred = pipeline.predict(X_test)\n",
    "results_df = pd.DataFrame(y_pred, columns=['预测结果'])\n",
    "results_df.to_csv('2.2.2_results.txt', index=False)\n",
    "\n",
    "# 测试模型\n",
    "with open('2.2.2_report.txt', 'w') as results_file:\n",
    "    results_file.write(f'训练集得分: {pipeline.score(X_train, y_train)}\\n')\n",
    "    results_file.write(f'测试集得分: {pipeline.score(X_test, y_test)}\\n')\n",
    "\n",
    "# 创建随机森林回归模型实例（创建的决策树的数量为100）\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# 训练随机森林回归模型\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "# 使用随机森林模型进行预测\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 保存新的结果\n",
    "results_rf_df = pd.DataFrame(y_pred_rf, columns=['预测结果'])\n",
    "results_rf_df.to_csv('2.2.2_results_rf.txt', index=False)\n",
    "\n",
    "# 测试模型并保存得分\n",
    "with open('2.2.2_report_rf.txt', 'w') as results_rf_file:\n",
    "    results_rf_file.write(f'训练集得分: {rf_model.score(X_train, y_train)}\\n')\n",
    "    results_rf_file.write(f'测试集得分: {rf_model.score(X_test, y_test)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a10d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b64fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
